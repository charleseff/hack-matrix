{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HackMatrix PureJaxRL Training on TPU (Colab)\n",
    "\n",
    "This notebook trains the HackMatrix game using PureJaxRL on Google Colab's free TPUs.\n",
    "\n",
    "**Before running:**\n",
    "1. Runtime → Change runtime type → TPU\n",
    "2. Run cells in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TPU is available\n",
    "import jax\n",
    "print(\"JAX version:\", jax.__version__)\n",
    "print(\"Devices:\", jax.devices())\n",
    "print(\"Device count:\", len(jax.devices()))\n",
    "print(\"Backend:\", jax.devices()[0].platform)\n",
    "\n",
    "if jax.devices()[0].platform != 'tpu':\n",
    "    print(\"\\n⚠️ WARNING: TPU not detected!\")\n",
    "    print(\"Go to: Runtime → Change runtime type → Hardware accelerator → TPU\")\n",
    "else:\n",
    "    print(\"\\n✅ TPU detected! Ready to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repository\n!git clone https://github.com/charleseff/hack-matrix.git\n%cd hack-matrix/python"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "print(\"✅ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Test (1K timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test to verify everything works\n",
    "!python scripts/train_purejaxrl.py \\\n",
    "  --num-envs 256 \\\n",
    "  --num-steps 128 \\\n",
    "  --total-timesteps 1000 \\\n",
    "  --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Medium Training (100K timesteps)\n",
    "\n",
    "This should take 1-2 minutes on TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/train_purejaxrl.py \\\n",
    "  --num-envs 1024 \\\n",
    "  --num-steps 256 \\\n",
    "  --total-timesteps 100000 \\\n",
    "  --save-interval 10 \\\n",
    "  --log-interval 5 \\\n",
    "  --checkpoint-dir checkpoints/colab_medium \\\n",
    "  --seed 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Training (10M timesteps)\n",
    "\n",
    "This should take 5-10 minutes on TPU. Adjust parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/train_purejaxrl.py \\\n",
    "  --num-envs 2048 \\\n",
    "  --num-steps 512 \\\n",
    "  --total-timesteps 10000000 \\\n",
    "  --learning-rate 0.0003 \\\n",
    "  --num-minibatches 8 \\\n",
    "  --update-epochs 4 \\\n",
    "  --hidden-dim 512 \\\n",
    "  --num-layers 3 \\\n",
    "  --save-interval 100 \\\n",
    "  --log-interval 10 \\\n",
    "  --checkpoint-dir checkpoints/colab_full \\\n",
    "  --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Checkpoints\n",
    "\n",
    "Download the trained model to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available checkpoints\n",
    "!ls -lh checkpoints/\n",
    "\n",
    "# Download final checkpoint\n",
    "from google.colab import files\n",
    "files.download('checkpoints/final_params.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Trained Agent (Optional)\n",
    "\n",
    "Test the trained agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add evaluation code here\n",
    "# This would load the checkpoint and run test episodes\n",
    "print(\"Evaluation script coming soon!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "### TPU Performance\n",
    "- Colab TPUs are v2-8 (8 cores) or v3-8 depending on availability\n",
    "- Expected throughput: 50K-100K steps/second\n",
    "- 10M timesteps should take 5-10 minutes\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "- `--num-envs`: More envs = better GPU/TPU utilization (try 1024-4096)\n",
    "- `--num-steps`: Longer rollouts = more stable gradients (try 256-1024)\n",
    "- `--learning-rate`: Start with 0.0003, reduce if training unstable\n",
    "- `--hidden-dim`: Larger network = more capacity (try 256-1024)\n",
    "\n",
    "### Memory Issues\n",
    "If you run out of memory:\n",
    "- Reduce `--num-envs` (try 1024 instead of 2048)\n",
    "- Reduce `--hidden-dim` (try 256 instead of 512)\n",
    "- Reduce `--num-steps` (try 256 instead of 512)\n",
    "\n",
    "### Session Limits\n",
    "- Colab has a 12-hour session limit (free tier)\n",
    "- Download checkpoints regularly to avoid losing progress\n",
    "- For longer training, consider TRC program or Colab Pro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}